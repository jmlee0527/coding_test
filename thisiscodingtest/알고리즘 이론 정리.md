## 목차

4. [정렬(Sorting)](#---sorting-)
5. [이진탐색 (Binary Search)](#------binary-search-)
6. [다이나믹 프로그래밍](#----------)
7. [최단 경로 알고리즘](#----------)
8. [그래프](#---)
## 정렬(Sorting)
정렬 : 데이터를 특정한 기준에 따라서 순서대로 나열하는 것

### 선택 정렬
가장 원시적인 방법으로 매번 가장 작은 데이터를 선택하는 정렬 방식이다.


즉, 먼저 가장 작은 데이터를 선택해 맨 앞의 데이터와 바꾸고 그다음 작은 데이터를 선택해 두번째 데이터와 바꾸는 과정을 반복하는 것이다.
이 과정을 반복하면 전체 데이터 정렬이 이루어진다.


"현재 정렬되지 않은 데이터 중 가장 작은 데이터", "이미 정렬된 데이터" 두가지를 확인하여 선택정렬 알고리즘을 사용할 수 있다.

#### <선택 정렬 소스코드>

    array = []

    for i in range(len(array)):
        min_index = i
        for j in range(i+1,len(array)):
            if array[min_index]>array[j]:
                min_index = j
        array[i], array[min_index] = array[min_index],array[i]

#### 시간복잡도
n-1번 만큼 가장 작은 수를 찾아서 맨 앞으로 보낸다. 또한 매번 최소값을 찾기 위한 비교 연산을 수행한다.


이때 비교 연산 횟수는 n + (n-1) + ... +2 이므로 n*(n_1)//2 만큼의 연산을 수행한다.


-> O(N^2)

### 삽입 정렬
삽입 정렬은 데이터를 하나씩 확인하며 해당 데이터를 적절한 위치에 삽입하도록 한다.


삽입 정렬은 필요시에만 위치를 수정하므로 데이터가 전체적으로 정렬되어있을 때 유리하게 사용될 수 있다.


삽입 정렬은 특정 데이터 이전의 데이터는 정렬되어있다는 가정하고 특정 데이터를 적절한 위치에 삽입한다.

#### <삽입 정렬 소스코드>

    array =[]
    for i in range(1,len(array)):
        for j in range(i,0,-1):
            if array[j] < array[j-1]
                array[j], array[j-1] = array[j-1],array[j]
            else:
                break

#### 시간복잡도
반복문이 2번 중첩되어 사용되었고 시간복잡도는 O(N^2)이다.


거의 정렬이 되어있는 경우에는 퀵 정렬보다 삽입 정렬을 사용하는 것이 효율적일 수 있으며 최적의 경우 O(N)의 시간복잡도를 갖는다.

### 퀵 정렬
가장 빠르게 동작하고 많이 사용되는 정렬 알고리즘이다.


기준이 되는 데이터를 설정하고 그 기준보다 큰 데이터와 작은 데이터를 바꾸는 방식을 반복한다.


리스트를 반으로 나누어 위와 같은 방식을 반복하는 분할 방식을 사용한다.


피벗(pivot)은 큰 숫자와 작은 숫자를 교환하기 위한 기준이 되는 값이다.

#### <퀵 정렬 소스코드>

    array = []

    def quick_sort(array):
        if len(array) <= 1:
            return array

        pivot = array[0]
        tail = array[1:]            #피벗을 제외한 나머지 리스트

        left_side = [x for x in tail if x<= pivot]
        right_side = [x for x in tail if x> pivot]

        return quick_sort(left_side) + [pivot] + quick_sort(right_side)
    
#### 시간복잡도
퀵 정렬의 경우 평균 시간 복잡도는 O(NlogN)이다. 하지만 최악의 경우 O(N^2)의 시간복잡도를 갖는다.(이미 정렬되어 있는 경우 매우 느리게 동작한다.)


이전의 두가지 정렬 방식에 비해 매우 빠른 편이다.


데이터의 개수가 많을 수록 시간 복잡도의 차이가 크다는 것을 확인할 수 있다.

### 계수 정렬
매우 빠른 정렬 알고리즘이지만 특정한 조건이 부합할 때만 사용할 수 있다.


계수 정렬은 데이터의 크기 범위가 제한 되어 정수 형태로 표현할 수 있을 때만 사용할 수 있다.


일반적으로 가장 큰 데이터와 가장 작은 데이터 차이가 1,000,000을 넘지 않을 때 효과적인 사용이 가능하다.


기존의 3가지 정렬 알고리즘처럼 직접 데이터 값을 비교한 뒤에 위치를 변경하는 방식이 아니다.


데이터의 최대값과 최소값에 해당하는 크기의 리스트를 선언하고 데이터 값과 동일한 인덱스의 데이터를 1씩 증가시키면서 계수 정렬을 한다.


정렬된 리스트의 인덱스 값에 해당하는 개수 만큼 인덱스 값을 출력하면 정렬된 출력값을 구할 수 있는 것이다.

#### <계수 정렬 소스코드>

    array =[7,5,9,0,3,1,6,2,9,1,4,8,0,5,2]
    count = [0]* (max(array)+1)

    for i in range(len(array)):
        count[array[i]] += 1

    for i in range(len(count)):
        for j in range(count[i]):
            print(i,end = ' ')

#### 공간 복잡도
계수 정렬은 비효율적인 경우도 발생하게 된다. 예를 들어 0,999999 두개의 데이터가 있는 경우에도 리스트의 크기가 100만개가 되도록 선언이 필요하기 때문이다.

즉, 계수 정렬은 동일한 값을 가지는 데이터가 여러 개 등장하는 경우 적절하게 사용될 수 있다.

계수 정렬의 공간 복잡도는 O(N+K)이다.

## 이진탐색 (Binary Search)
### 순차 탐색
리스트 안에 있는 특정한 데이터를 찾기 위해 앞에서부터 데이터를 순차적으로 확인하는 방법

#### <순차 탐색 소스코드>

    def sequential_search(n,target,array):
        for i in range(n):
            if array[i] == target:
                return i+1

### 이진 탐색
이진 탐색은 배열의 데이터가 정렬되어 있을 때만 사용할 수 있다.


시작점,끝점,중간점 3개의 변수를 사용하여 찾는 데이터와 중간점 위치에 있는 데이터를 반복적으로 비교하여 원하는 값을 찾는 알고리즘이다.


이진 탐색의 경우 한 번 확인 시 데이터가 절반씩 줄어들어 효율적으로 O(logN)의 시간복잡도를 갖는다.

#### <이진 탐색 소스코드 - 재귀 함수>

    def binary_search(array,target,start,end):
        if start > end:
            return None
        mid = (start + end)//2

        if array[mid] == target:
            return mid
        elif array[mid] > target:
            return binary_search(array,target,start,mid-1)
        else:
            return binary_search(array,target,mid+1,end)

#### <이진 탐색 소스코드 - 반복문>

    def binary_search(array,target,start,end):
        while start <= end:
            mid = (start+end) //2
            if array[mid] == target:
                return mid
            elif array[mid] > target:
                end = mid -1
            else:
                start = mid +1
        return None 

## 다이나믹 프로그래밍
다이나믹 프로그래밍은 기본적인 아이디어로 하나의 큰 문제를 여러 개의 작은 문제로 나누어서 그 결과를 저장하여 다시 큰 문제를 해결할 때 사용하는 방식이다.

#### 다이나믹 프로그래밍의 조건
1. 큰 문제를 작은 문제로 나눌 수 있다.
2. 작은 문제에서 구한 정답은 그것을 포함하는 큰 문제에서도 동일하다.


메모이제이션(캐싱) : 다이나믹 프로그래밍을 구현하는 방법 중 한 종류로, 한번 구한 결과를 메모리 공간에 메모해두고 같은 식을 다시 호출하면 메모한 결과를 그대로 가져오는 기법


즉, 한번 구한 결과값을 매번 다시 구하지 않고 결과를 저장해두고 바로 사용하여 실행 시간을 줄일 수 있다.

일반적으로 재귀함수 대신에 반복문을 사용하는 경우 오버헤드를 줄일 수 있다.


Top-Down 방식 : 큰 문제를 해결하기 위해 작은 문제를 호출하는 방식


Bottom-Up 방식 : 작은 문제부터 차근차근 답을 구하여 올라가는 방식

#### <피보나치 소스코드 - 재귀 함수>

    d = [0] * 100       #메모제이션을 위한 리스트 초기화

    def fibo(x):
        if x == 1 or x == 2:
            return 1
        if d[x] != 0:
            return d[x]
        d[x] = fibo(x-1) + fibo(x-2)
        return d[x]

#### <피보나치 소스코드 - 반복>

    d = [0] * 100       #메모제이션을 위한 리스트 초기화

    d[1] = 1
    d[2] = 1
    for i in range(3,n+1):
        d[i] = d[i-1] + d[i-2]
    
## 최단 경로 알고리즘
1. 다익스트라 최단 경로 알고리즘
2. 플로이드 워셜
3. 벨만 포드 알고리즘

### 다익스트라 최단 경로 알고리즘
그래프에서 여러 개의 노드가 있을 때, 특정 노드에서 출발하여 다른 노드로 가는 각각의 최단 경로를 구해주는 알고리즘
단, 음의 간선이 없을 때 정상적으로 동작한다.
매번 비용이 가장 적은 노드르 선택하여 그리디 알고리즘으로 분류되기도 한다.

출발 노드 설정 -> 최단 거리 테이블 초기화 -> 방문하지 않은 노드중 최단 거리 노드 선택 -> 최단 거리 테이블 갱신하며 반복

### 간단한 다익스트라 알고리즘
매 단계마다 방문하지 않은 노드 중에서 최단 거리가 가장 짧은 노드를 선택하기 위해 1차원 리스트를 순차탐색한다.
O(V^2)의 시간 복잡도를 갖는다. (V-> 노드의 개수)

#### <간단한 다익스트라 알고리즘 소스코드>

    impmort sys
    input = sys.stdin.readline
    INF = int(1e9)

    n,m = map(int,input().split())
    start = int(input())
    graph = [[] for i in range(n+1)]
    visited = [False]* (n+1)
    distance = [INF] * (n+1)

    for _ in range(m):
        a,b,c = map(int,input().split())
        graph[a].append((b,c))

    def get_smallest_node():
        min_value = INF
        index = 0
        for i in range(1,n+1):
            if distance[i] < min_value and not visitded[i]:
                min_value = distance[i]
                index = i
        return index

    def dijkstra(start):
        distance[start] = 0
        visitded[start] = True
        for j in graph[start]:
            distance[j[0]] = j[1]
        for i in range(n-1):
            now = get_smallest_node()
            visited[now] = True
            for j in graph[now]:
                cost = distance[now]+j[1]
                if cost < distance[j[0]]:
                    distance[j[0]] = cost
    dijkstra(start)

    for i in range(1,n+1):
        if distance[i] == INF:
            print("INFINITY")
        else:
            print(distance[i])

### 개선된 다익스트라 알고리즘
개선된 다익스트라 알고리즘을 사용하는 경우 시간복잡도 O(ElogV)를 갖는다. (V->노드 수 , E-> 간선의 개수)
개선된 다익스트라 알고리즘에서는 힙 자료구조를 사용하여 특정 노드까지의 최단 거리에 대한 정보를 담아서 빠르게 탐색이 가능하다.

#### <개선된 다익스트라 알고리즘 소스코드>

    import heapq
    import sys
    input = sys.stdin.readline
    INF = int(1e9)

    #노드,간선의 개수 입력
    n,m = map(int,input().split())
    #시작 노드 번호 입력
    start = int(input())
    #노드간의 연결 정보
    graph = [[] for i in range(n+1)]
    #최단 거리 테이블 초기화
    distance = [INF]*(n+1)

    #간선의 정보 입력 받기
    for _ in range(m):
        a,b,c = map(int, input().split())
        #a 노드에서 b로 가는 비용이 c
        graph[a].append((b,c))

    def dijkstra(start):
        q = []
        #시작 노드로 가기 위한 최단 경로는 0, 큐에 삽입
        heapq.heappus(q,(0,start))
        distance[start] = 0
        while q:
            #가장 최단 거리가 짧은 노드 정보 꺼내기
            dist,now = heapq.heappop(q)
            #이미 처리된 노드인 경우 무시
            if distance[now] <dist:
                continue
            #현재노드의 인접 노드 확인 
            for i in graph[now]:
                cost = dist +i[1]
                #현재 노드를 거쳐 다른 노드 이동 거리가 짧은 경우
                if cost < distance[i[0]]:
                    distance[i[0]] = cost
                    heapq.heqppush(q,(cost,i[0]))
    dijkstra(start)

    #모든 노드로 가는 최단 거리 출력
    for i in range(1,n+1):
        if distance[i] == INF:
            print("INFINITY")
        else:
            print(distance[i])
        
### 플로이드 워셜 알고리즘
플로이드 워셜 알고리즘은 모든 지점에서 다른 모든 지점까지의 최단 경로를 모두 구해야 하는 경우에 사용하는 알고리즈이다.


바로 이동하는 거리와 특정한 노드를 거쳐서 이동하는 거리를 비교하여 최소값으로 갱신하는 것이다.


3중 반복문을 사용하여 O(N^3)의 시간복잡도를 갖는다.


#### 플로이드 워셜 알고리즘 소스코드

    INF = int(1e9)

    #노드의 개수 및 간선 개수 입력
    n = int(input())
    m = int(input())

    #2차원 리스트를 만들고 모든 값을 무한으로 초기화
    graph = [[INF]*(n+1) for _ in range(n+1)]

    #자기 자신에서 자기 자신으로 가는 비용은 0
    for a in range(1,n+1):
        for b in range(1,n+1):
            if a == b:
                graph[a][b] = 0

    #각 간선에 대한 정보를 입력받아 초기화
    for _ in range(m):
        #A에서 B로가는 비용 C
        a,b,c = map(int,input().split())
        graph[a][b] = c

    #플로이드 워셜 알고리즘
    for k in range(1,n+1):
        for a in range(1,n+1):
            for b in range(1,n+1):
                graph[a][b] = min(graph[a][b],graph[a][k]+graph[k][b])

    #결과 출력
    for a in range(1,n+1):
        for b in range(1, n+1):
            if graph[a][b] = INF:
                print("INFINITY", end = " ")
            else:
                print("graph[a][b], end = " ")
        print()

## 그래프
### 서로소 집합
서로소 집합 : 공통 원소가 없는 두 집합
서로소 집합 자료구조 : 서로소 부분 집합들로 나누어진 원소들의 데이터를 처리하기 위한 자료 구조(union, find)

#### 서로소 집합 계산 알고리즘 과정
1. union(합집합) 연산을 확인하여 서로 연결된 두 노드 A,B를 확인한다.
2. A,B의 루트노드 a,b를 각각 찾는다.
3. a를 b의 부모노드로 설정한다.(a,b중 작은 것을 부모노드로 구현하는 것이 일반적)
4. 위 과정을 반복한다.

union 연산을 수행하기 위해 부모 테이블을 항상 가지고 있어야한다.


서로소 집합 알고리즘으로 루트를 찾기 위해서는 재귀적으로 부모를 거슬러 올라가는 과정이 필요하다.

#### <서로소 집합 알고리즘 소스코드>
    def find_parent(parent,x):          #특정원소가 속한 집합을 찾기
        #루트 노드를 찾을 때까지 재귀적으로 호출
        if parent[x] != x:
            return find_parent(parent,parent[x])
        return x
    
    def union_parent(parent,a,b):
        a = find_parent(parent,a)
        b = find_parent(parent,b)
        if a<b:
            parent[b] = a
        else:
            parent[a] = b
        
    v,e = map(int,input().split())
    parent = [0] *(v+1)

    for i in range(1,v+1):
        parent[i] = i

    for i in range(e):
        a,b, = map(int,input().split())
        union_parent(parent,a,b)
    
    print("각 원소가 속한 집합:",end = "")

    for i in range(1,v+1):
        print(find_parent(parent,i),end = "")

    print()

    print("부모 테이블:", end =" ")
    for i in range(1,v+1):
        print(parent[i],end = " ")
    
    #경로 압축 기법을 이용하여 find_parent함수를 다음과 같이 수정하면 시간 복잡도를 개선할 수 있다.

    def find_parent(parent,x):
        if parent[x] != x:
            parent[x] = find_parent(parent,parent[x])
        return parent[x]

### 사이클 판별 알고리즘

그래프에 포함되어 있는 간선의 개수가 E개 일때 모든 간선을 하나씩 확인하며 매 간선에 대하여 union 및 find 함수를 호출하는 방식으로 동작 (간선에 방향성이 없는 경우만 가능)

1. 각 간선을 확인하며 두 노드의 루트 노드를 확인한다.
2. 루트 노드가 다르다면 union 연산 수행
3. 루트 노드가 서로 같다면 사이클이 발생
4. 위 과정을 반복하여 확인


<서로소 집합을 활용한 사이클 판별 소스코드>
    def find_parent(parent,x):
        if parent[x] != x:
            parent[x] = find_parent(parent,parent[x])
        return parent[x]
    
    def union_parent(parent,a,b):
        a = find_parent(parent,a)
        b = find_parent(parent,b)
        if a<b:
            parent[b] = a
        else:
            parent[a] = b
        
    v,e = map(int,input().split())
    parent = [0] *(v+1)

    for i in range(1,v+1):
        parent[i] = i

    cycle = False

    for i in range(e):
        a,b = map(int,input().split())
        if find_parent(parent,a) == find_parent(parent,b):
            cycle = True
            break
        else:
            union_parent(parent,a,b)
    
    if cycle:
        print("사이클이 발생했습니다.")
    else:
        print("사이클이 발생하지 않았습니다.")

### 신장 트리
신장 트리 : 하나의 그래프가 있을 때 모든 노드를 포함하면서 사이클이 존재하지 않는 부분 그래프

### 크루스칼 알고리즘
N개의 도시가 존재하는 상황에서 두 도시 사이의 도로를 놓아 전체 도시가 서로 연결될 수 있도록 설치하는 경우 최소 비용으로 연결하기 위한 문제를 해결할 때 사용되는 대표적인 최소 신장 트리 알고리즘


즉, 가장 적은 비용으로 모든 노드를 연결할 수 있는 알고리즘이다.(그리디 알고리즘의 하나)


모든 간선에 대하여 정렬을 수행한 뒤에 가장 거리가 짧은 간선부터 집합에 포함시킨다. 이때, 사이클을 발생시킬 수 있는 간선의 경우 포함시키지 않는다.

1. 간선 데이터를 비용에 따라 오름차순으로 정렬
2. 간선을 하나씩 확인하며 현재의 간선이 사이클을 발생시키는지 확인
3. 사이클이 발생하지 않는 경우 최소 신장 트리에 포함, 그렇지 않은 경우 포함x
4. 모든 간선에 대하여 반복

#### <크루스칼 알고리즘 소스코드>


    def find_parent(parent,x):
        if parent[x] != x:
            parent[x] = find_parent(parent,parent[x])
        return parent[x]
    
    def unioin_parent(parent,a,b):
        a = find_parent(parent,a)
        b = find_parent(parent,b)
        if a < b :
            parent[b] = a
        else:
            parent[a] = b
        
    v,e = map(int,input().split())
    parent = [0] * (v+1)

    edges = []      #간선을 담을 리스트
    result = 0

    for i in range(1,v+1):
        parent[i] = i
    
    for _ in range(e):
        a,b,cost = map(int,input().split())
        edges.append((cost,a,b))        #비용순 정렬을 위해 첫번째 요소를 비용으로 설정
    
    edges.sort()

    for edge in edges:
        cost,a,b = edge
        if find_parent(parent,a) != find_parent(parent,b):
            union_parent(parent,a,b)
            result += cost
    
    print(result)


크루스칼 알고리즘은 간선의 개수가 E개일 때 O(ElogE)의 시간복잡도를 가진다.

### 위상 정렬(Topology Sort)
위상 정렬 : 방향 그래프의 모든 노드를 "방향성에 거스르지 않도록 순서대로 나열하는 것"

위상 정렬 알고리즘 동작 과정
1. 진입차수가 0인 노드를 큐에 넣는다.
2. 큐가 빌 때까지 다음 과정을 반복
3. 큐에서 원소를 꺼내 해당 노드에서 출발하는 간선을 그래프에서 제거한다.
4. 새롭게 진입차수가 0이 된 노드를 큐에 넣는다.

#### <위상 정렬 소스코드>
    from collections import deque

    v,e = map(int,input().split())
    indegree = [0] * (v+1)
    graph = [[] for i in range(v+1)]

    for _ in range(e):
        a,b, = map(int,input().split())
        graph[a].append(b)
        indegree[b] += 1

    def topologt_sort():
        result = []
        q = deque()

        for i in range(1,v+1):
            if indegree[i] == 0:
                q.append(i)
        
        while q:
            now = q.popleft()
            result.append(now)
            for i in graph[now]:
                indegree[i] -= 1
                if indegree[i] == 0:
                    q.append(i)
    for i in result:
        print(i,end=" ")
    
    topology_sort()

위상 정렬을 수행할 때 차례대로 모든 노드를 확인하면서 출발하는 간선을 제거하므로 노드와 간선을 모두 확인하는 과정에서 O(V+E)의 시간 복잡도를 갖는다.